[TOC]

# 数据结构

## hashmap和hashtable的区别

* 继承与实现的区别

  * hashmap 继承于实现了 Map 接口的 AbstractMap ；
  * hashtable 继承于实现了 Map 接口的 Dictionary（字典），由于设计上的缺陷，现在不推荐使用；

* 线程安全不同

  * HashTable的方法是同步的，HashMap是未同步，所以在多线程场合要手动同步HashMap。
  * **HashMap给出了他自己的解决并发办法，多线程需要使用HashMap建议**采用concurrent并发包下的concurrentHashMap。

* 对null的处理不同

  * HashTable不允许null值(key和value都不可以),HashMap允许null值(key和value都可以)。即 HashTable不允许null值其实在编译期不会有任何的不一样，会照样执行，只是在运行期的时候Hashtable中设置的话回出现空指针异常。 HashMap允许null值是指可以有一个或多个键所对应的值为null。（key 也可以为 null,源码中对于这种情况做出了处理，存放于 table[0] 链表的表头）当get()方法返回null值时，既可以表示 HashMap中没有该键，也可以表示该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键，而应该用containsKey()方法来判断。

* HashTable使用Enumeration（列举），HashMap使用Iterator（迭代器）。

* 扩容方式不同：HashTable中hash数组默认大小是11，增加的方式是 old\*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。根据HashMap的实现，它在每次扩容后的容量是原先的一倍。扩充结果都为2的幂次方大小。即HashMap总是使用2的幂作为哈希表的大小。这样做可以成倍提升计算Hash值的效率，为什么这么说呢？因为HashMap大小是2的幂次方，所以它使用取模计算时，可以直接使用位运算来得到结果，效率大大高于以前使用除法的效率。比如在HashMap执行增加、删除、查找键值对时，定位到哈希位置是很关键的一步，源码中是通过下面3个操作来完成这一步：1）拿到key的hashCode值；2）将hashCode的高位参与运算，重新计算hash值；3）将计算出来的hash值与(table.length - 1)进行&运算。

* 哈希值的使用：HashTable直接使用对象的hashCode，代码是这样的：

  ~~~java
  int hash = key.hashCode();

  　　int index = (hash & 0x7FFFFFFF) % tab.length;

  　　//而HashMap重新计算hash值，而且用位运算代替求模

  ~~~


## 平衡二叉树（AVL树）

* 参考至`<https://www.cnblogs.com/qiumingcheng/p/4738661.html>`

### 定义

*  父节点的左子树和右子树的高度之差不能大于1，也就是说不能高过1层，否则该树就失衡了，此时就要旋转节点，在

  编码时，我们可以记录当前节点的高度，比如空节点是-1，叶子节点是0，非叶子节点的height往根节点递增。

* 它的左子树和右子树都是平衡二叉树。

* 又称为AVL树，AVL树是二分搜索树。

### 怎么形成平衡二叉树

* 当插入一个数据到二叉树后，如果此时破坏了平衡二叉树的结构，那么我们就需要去调整它,先找到失衡点，然后再旋转；

  ① 左左情况（左子树的左边节点）

  ![img](https://pic002.cnblogs.com/images/2012/214741/2012072218213884.png)

  我们看到，在向树中追加“节点1”的时候，根据定义我们知道这样会导致了“节点3"失衡，满足“左左情况“，此时我们就可以把失衡节点设置成根节点，然后调整它的右树即可

  ② 右右情况（右子树的右边节点）

  ![img](https://pic002.cnblogs.com/images/2012/214741/2012072218444051.png)

  同样，”节点5“满足”右右情况“，其实我们也看到，这两种情况是一种镜像，当然操作方式也大同小异，此时我们就可以把失衡节点设置成根节点，然后调整它的左书即可

   

  ③左右情况（左子树的右边节点），处理思想是将左右情况变成左左情况，然后再处理

  ![img](https://pic002.cnblogs.com/images/2012/214741/2012072219144367.png)

  从图中我们可以看到，当我们插入”节点3“时，“节点5”处失衡，注意，找到”失衡点“是非常重要的，当面对”左右情况“时，我们将失衡点的左子树进行"右右情况旋转"，然后进行”左左情况旋转“，经过这样两次的旋转就OK了，很有意思，对吧。

   

  ④右左情况(右子树的左边节点）处理思想：是将右左情况变成右右情况，然后再处理

  ![img](https://pic002.cnblogs.com/images/2012/214741/2012072219540371.png)

* 验证是否已经是平衡二叉树：中序遍历所得关键字的值序列从小到大即可（二叉排序树的性质）

## 简单了解红黑树

* 红黑树比较传统的定义是需要满足以下五个特征：
  （1）每个节点或者是黑色，或者是红色。
  （2）根节点是黑色。
  （3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
  （4）如果一个节点是红色的，则它的子节点必须是黑色的。
  （5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。
  其特点在于给数的每一个节点加上了颜色属性，在插入的过程中通过颜色变换和节点旋转调平衡。

## LruCache 与 LinkedHashMap

* `https://juejin.im/post/5b8f15e26fb9a01a031b12d9`

LinkedHashMap:LinkedHashMap与HashMap在很多地方都是相同的，LinkedHashMap时HashMap的子类，键不可重复，值可重复，底层依然采用哈希表存储，线程不安全，允许key和value为空。只是在LikedHashMap重写了newNode（）方法，在newNode方法中将每个新生成的节点与已经存在的节点用双向链表链接起来了，其实LinkedHashMap中put方法就是使用的父类HashMap的中的put方法，只是重新的newNode方法实现了节点的双向链表结构，因此可以理解为LinkedHashMap既采用了哈希表（拉链法和红黑树）存储，也采用了双向链表存储。此外LinkedHashMap的遍历方式与HashMap也是不一样的，LinkedHashMap的遍历方式是遍历双向链表。HashMap的遍历是根据节点数组（桶）来遍历拉链节点。

LruCache 的核心原理就是对 LinkedHashMap 的有效利用，它的内部存在一个 LinkedHashMap 成员变量。值得我们关注的有四个方法：**构造方法、get、put、trimToSize。**

- **构造方法：** 在 LruCache 的构造方法中做了两件事，设置了 maxSize、创建了一个 LinkedHashMap。这里值得注意的是 LruCache 将 LinkedHashMap的accessOrder 设置为了 true，accessOrder 就是遍历这个LinkedHashMap 的输出顺序。true 代表按照访问顺序输出，false代表按添加顺序输出，因为通常都是按照添加顺序输出，所以 accessOrder 这个属性默认是  false，但我们的 LruCache 需要按访问顺序输出，所以显式的将 accessOrder  设置为 true。
- **get方法：** 本质上是调用 LinkedHashMap 的 get 方法，由于我们将 accessOrder 设置为了 true，所以每调用一次get方法，就会将我们访问的当前元素放置到这个LinkedHashMap的尾部。
- **put方法：** 本质上也是调用了 LinkedHashMap 的 put 方法，由于 LinkedHashMap 的特性，每调用一次 put 方法，也会将新加入的元素放置到 LinkedHashMap 的尾部。添加之后会调用 trimToSize 方法来保证添加后的内存不超过 maxSize。
- **trimToSize方法：** trimToSize 方法的内部其实是开启了一个 while(true)的死循环，不断的从 LinkedHashMap 的首部删除元素，直到删除之后的内存小于 maxSize 之后使用 break 跳出循环。

* 其实到这里我们可以总结一下，为什么这个算法叫 **最近最少使用**(Least Recently Used) 算法呢？原理很简单，我们的每次 put 或者get都可以看做一次访问，由于 LinkedHashMap 的特性，会将每次访问到的元素放置到尾部。当我们的内存达到阈值后，会触发 trimToSize 方法来删除 LinkedHashMap 首部的元素，直到当前内存小于 maxSize。为什么删除首部的元素，原因很明显：我们最近经常访问的元素都会放置到尾部(由双向链表控制)，那首部的元素肯定就是 **最近最少使用** 的元素了，因此当内存不足时应当优先删除这些元素。

### DiskLruCache

设计一个图片加载框架，肯定要用到图片加载的三级缓存的思想。三级缓存分为内存缓存、本地缓存和网络缓存。

内存缓存：将Bitmap缓存到内存中（一般用的都是 LruCache），运行速度快，但是内存容量小。 本地缓存（ DiskLruCache）：将图片缓存到硬盘文件中，速度较慢，但容量较大。 网络缓存：从网络获取图片，速度受网络影响。

如果我们设计一个图片加载框架，流程一定是这样的：

- 拿到图片url后首先从内存中查找BItmap，如果找到直接加载。
- 内存中没有找到，会从本地缓存中查找，如果本地缓存可以找到，则直接加载。
- 内存和本地都没有找到，这时会从网络下载图片，下载到后会加载图片，并且将下载到的图片放到内存缓存和本地缓存中。